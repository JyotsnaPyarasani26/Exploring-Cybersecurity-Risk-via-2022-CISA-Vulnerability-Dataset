from pyspark.sql import SparkSession

# Step 1: Create a SparkSession
spark = SparkSession.builder.appName("CybersecurityRiskAnalysis").getOrCreate()

# Step 2: Load each CSV file into separate DataFrames
file1_path = r"C:\Users\Administrator\Downloads\assign2\2022-06-08-enriched.csv"
file2_path = r"C:\Users\Administrator\Downloads\assign2\2022-06-09-enriched.csv"
file3_path = r"C:\Users\Administrator\Downloads\assign2\2022-06-27-enriched.csv"
file4_path = r"C:\Users\Administrator\Downloads\assign2\2022-07-04-enriched.csv"
file5_path = r"C:\Users\Administrator\Downloads\assign2\2022-12-09-enriched.csv"

df1 = spark.read.csv(file1_path, header=True, inferSchema=True)
df2 = spark.read.csv(file2_path, header=True, inferSchema=True)
df3 = spark.read.csv(file3_path, header=True, inferSchema=True)
df4 = spark.read.csv(file4_path, header=True, inferSchema=True)
df5 = spark.read.csv(file5_path, header=True, inferSchema=True)

# Step 3: Combine the DataFrames using the union() method
combined_df = df1.union(df2).union(df3).union(df4).union(df5)

# Step 4: Show a sample of the combined DataFrame to verify the data
combined_df.show()
